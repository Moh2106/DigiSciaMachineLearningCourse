{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eee520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5440ad0",
   "metadata": {},
   "source": [
    "## Cours sur la Régression Logistique\n",
    "\n",
    "### 1. **Introduction à la Régression Logistique**\n",
    "\n",
    "La régression logistique est une technique de machine learning supervisé utilisée pour la classification binaire, c'est-à-dire pour prédire l'appartenance d'une observation à l'une de deux classes. Contrairement à la régression linéaire, qui prédit des valeurs continues, la régression logistique prédit une probabilité qui peut ensuite être convertie en une classe.\n",
    "\n",
    "### 2. **Concepts Clés**\n",
    "\n",
    "#### **2.1. Fonction Logistique (Sigmoïde)**\n",
    "\n",
    "La régression logistique repose sur la fonction logistique, aussi appelée fonction sigmoïde, qui est définie comme suit :\n",
    "\n",
    "\\[\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "\\]\n",
    "\n",
    "où :\n",
    "- \\( z \\) est une combinaison linéaire des caractéristiques d'entrée,\n",
    "- \\( \\sigma(z) \\) renvoie une valeur comprise entre 0 et 1, représentant une probabilité.\n",
    "\n",
    "#### **2.2. Modèle de Régression Logistique**\n",
    "\n",
    "Le modèle de régression logistique prend la forme suivante :\n",
    "\n",
    "\\[\n",
    "p(y=1|X) = \\sigma(\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_nx_n)\n",
    "\\]\n",
    "\n",
    "où :\n",
    "- \\( p(y=1|X) \\) est la probabilité que la variable cible \\( y \\) soit égale à 1,\n",
    "- \\( \\beta_0 \\) est l'intercept (ordonnée à l'origine),\n",
    "- \\( \\beta_1, \\beta_2, \\dots, \\beta_n \\) sont les coefficients des caractéristiques \\( x_1, x_2, \\dots, x_n \\),\n",
    "- \\( X \\) est le vecteur des caractéristiques.\n",
    "\n",
    "### 3. **Interprétation des Résultats**\n",
    "\n",
    "#### **3.1. Probabilité et Prédiction**\n",
    "\n",
    "La sortie du modèle est une probabilité, et pour faire une prédiction de classe (0 ou 1), un seuil est appliqué. Par défaut, le seuil est de 0,5 :\n",
    "\n",
    "- Si \\( p(y=1|X) \\geq 0.5 \\), alors \\( \\hat{y} = 1 \\) (classe positive).\n",
    "- Si \\( p(y=1|X) < 0.5 \\), alors \\( \\hat{y} = 0 \\) (classe négative).\n",
    "\n",
    "#### **3.2. Coefficients (β)**\n",
    "\n",
    "Les coefficients \\( \\beta \\) dans un modèle de régression logistique sont interprétés en termes de changement logarithmique des cotes (odds). Le logarithme des cotes est linéairement lié aux caractéristiques.\n",
    "\n",
    "\\[\n",
    "\\text{logit}(p) = \\log\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1x_1 + \\dots + \\beta_nx_n\n",
    "\\]\n",
    "\n",
    "Les cotes représentent le rapport des probabilités d'un événement se produisant par rapport à l'événement inverse.\n",
    "\n",
    "### 4. **Entraînement du Modèle**\n",
    "\n",
    "#### **4.1. Fonction de Coût (Log-Loss)**\n",
    "\n",
    "La fonction de coût pour la régression logistique est la log-vraisemblance négative (ou log-loss), qui mesure la divergence entre les prédictions du modèle et les étiquettes réelles.\n",
    "\n",
    "\\[\n",
    "\\text{Cost} = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log(p_i) + (1-y_i) \\log(1-p_i) \\right]\n",
    "\\]\n",
    "\n",
    "où :\n",
    "- \\( m \\) est le nombre d'observations,\n",
    "- \\( y_i \\) est la valeur réelle de la classe,\n",
    "- \\( p_i \\) est la probabilité prédite par le modèle.\n",
    "\n",
    "#### **4.2. Optimisation**\n",
    "\n",
    "Le modèle de régression logistique est ajusté en minimisant la fonction de coût à l'aide de techniques d'optimisation telles que la descente de gradient.\n",
    "\n",
    "### 5. **Exemple Concret avec `scikit-learn`**\n",
    "\n",
    "#### **Étape 1 : Importation des Bibliothèques**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "```\n",
    "\n",
    "#### **Étape 2 : Chargement et Préparation des Données**\n",
    "\n",
    "Nous utiliserons ici un dataset fictif sur l'admission à l'université basé sur les scores des tests d'admission :\n",
    "\n",
    "```python\n",
    "# Exemple de dataset\n",
    "data = {\n",
    "    'score_test1': [34, 78, 67, 89, 45, 56, 72, 83, 91, 67],\n",
    "    'score_test2': [78, 85, 95, 65, 50, 70, 88, 60, 62, 55],\n",
    "    'admission': [0, 1, 1, 1, 0, 0, 1, 0, 1, 0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "X = df[['score_test1', 'score_test2']]\n",
    "y = df['admission']\n",
    "```\n",
    "\n",
    "#### **Étape 3 : Division des Données en Ensembles d'Entraînement et de Test**\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "#### **Étape 4 : Entraînement du Modèle**\n",
    "\n",
    "```python\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "#### **Étape 5 : Prédictions et Évaluation**\n",
    "\n",
    "```python\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "```\n",
    "\n",
    "### 6. **Métriques d'Évaluation**\n",
    "\n",
    "#### **Accuracy**\n",
    "Proportion de prédictions correctes sur l'ensemble des prédictions.\n",
    "\n",
    "#### **Matrice de Confusion**\n",
    "Tableau qui montre les prédictions correctes et incorrectes pour chaque classe.\n",
    "\n",
    "#### **Rapport de Classification**\n",
    "Il fournit des informations détaillées sur la précision (precision), le rappel (recall), et le F1-score pour chaque classe.\n",
    "\n",
    "### 7. **Avantages et Limitations de la Régression Logistique**\n",
    "\n",
    "#### **Avantages :**\n",
    "- **Simplicité** : Facile à interpréter et à implémenter.\n",
    "- **Efficacité** : Fonctionne bien avec des datasets de petite à moyenne taille.\n",
    "- **Probabilités** : Fournit des probabilités, ce qui est utile dans des applications sensibles au risque.\n",
    "\n",
    "#### **Limitations :**\n",
    "- **Linéarité** : Suppose une relation linéaire entre les caractéristiques et le logit, ce qui peut être limitatif pour les relations complexes.\n",
    "- **Classification Binaire** : Conçu pour la classification binaire, bien qu'il puisse être étendu à la classification multiclasse (par exemple, avec l'approche \"one-vs-rest\").\n",
    "\n",
    "### 8. **Conclusion**\n",
    "\n",
    "La régression logistique est un outil puissant pour les problèmes de classification binaire. Sa simplicité et son efficacité en font un choix privilégié pour de nombreux problèmes de machine learning, en particulier lorsque les relations entre les variables sont approximativement linéaires. Pour des relations plus complexes, des techniques supplémentaires telles que la régularisation, la transformation des caractéristiques ou l'utilisation d'autres algorithmes de classification peuvent être nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbffa56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
