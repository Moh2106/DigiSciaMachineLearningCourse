{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4e2ff2b",
   "metadata": {},
   "source": [
    "## Cours sur la Classification en Machine Learning\n",
    "\n",
    "### 1. **Introduction à la Classification**\n",
    "\n",
    "La classification est une technique de machine learning supervisé où l'objectif est de prédire la catégorie ou la classe d'une observation donnée, en se basant sur des caractéristiques ou des attributs. Contrairement à la régression, où la sortie est continue, la classification produit des résultats discrets, c'est-à-dire des étiquettes ou des classes.\n",
    "\n",
    "#### **Exemples de Problèmes de Classification :**\n",
    "- **Reconnaissance d'image** : Classifier des images de chats et de chiens.\n",
    "- **Détection de spam** : Identifier si un email est un spam ou non.\n",
    "- **Prédiction de maladies** : Diagnostiquer si un patient est atteint d'une certaine maladie ou non.\n",
    "\n",
    "### 2. **Types de Classification**\n",
    "\n",
    "#### **Classification Binaire :**\n",
    "Un problème de classification avec deux classes (par exemple, malade vs non malade).\n",
    "\n",
    "#### **Classification Multiclasse :**\n",
    "Un problème de classification avec plus de deux classes (par exemple, classer un fruit comme une pomme, une banane ou une orange).\n",
    "\n",
    "#### **Classification Multilabel :**\n",
    "Chaque observation peut appartenir à plusieurs classes simultanément (par exemple, taguer une image avec plusieurs objets).\n",
    "\n",
    "### 3. **Les Différents Algorithmes de Classification**\n",
    "\n",
    "#### **3.1. Régression Logistique**\n",
    "\n",
    "La régression logistique est un modèle de classification binaire qui prédit la probabilité qu'une observation appartienne à une certaine classe.\n",
    "\n",
    "- **Fonctionnement** : Elle utilise une fonction logistique pour modéliser la relation entre les caractéristiques et la probabilité d'appartenir à la classe cible.\n",
    "- **Avantages** : Simple à interpréter, fonctionne bien pour les petites datasets et les classes bien séparées.\n",
    "- **Inconvénients** : Performances limitées pour les classes non linéairement séparables.\n",
    "\n",
    "#### **3.2. k-Nearest Neighbors (k-NN)**\n",
    "\n",
    "Le k-NN est un algorithme non paramétrique qui classe une observation en fonction des classes des k observations les plus proches dans l'espace des caractéristiques.\n",
    "\n",
    "- **Fonctionnement** : Il mesure la distance (souvent euclidienne) entre l'observation et les autres observations dans le dataset.\n",
    "- **Avantages** : Facile à comprendre et à implémenter, pas d'entraînement nécessaire.\n",
    "- **Inconvénients** : Peut être lent pour des datasets volumineux, sensible au bruit et aux valeurs aberrantes.\n",
    "\n",
    "#### **3.3. Arbres de Décision**\n",
    "\n",
    "Les arbres de décision sont des modèles de classification qui segmentent l'espace des caractéristiques en divisions hiérarchiques basées sur les valeurs des caractéristiques.\n",
    "\n",
    "- **Fonctionnement** : Chaque nœud de l'arbre représente une condition basée sur une caractéristique, et les feuilles représentent les classes.\n",
    "- **Avantages** : Facile à interpréter, fonctionne bien avec des données catégorielles.\n",
    "- **Inconvénients** : Tendance à l'overfitting, particulièrement avec des arbres profonds.\n",
    "\n",
    "#### **3.4. Forêts d'Arbres Décisionnels (Random Forests)**\n",
    "\n",
    "Une forêt d'arbres décisionnels est un ensemble d'arbres de décision utilisés ensemble pour améliorer la précision et réduire l'overfitting.\n",
    "\n",
    "- **Fonctionnement** : Chaque arbre est entraîné sur un sous-échantillon des données, et la prédiction finale est obtenue par un vote majoritaire parmi les arbres.\n",
    "- **Avantages** : Robuste aux overfitting, fonctionne bien avec des jeux de données complexes.\n",
    "- **Inconvénients** : Moins interprétable que les arbres de décision individuels.\n",
    "\n",
    "#### **3.5. Support Vector Machines (SVM)**\n",
    "\n",
    "Les SVM sont des modèles de classification qui trouvent un hyperplan optimal pour séparer les classes dans l'espace des caractéristiques.\n",
    "\n",
    "- **Fonctionnement** : L'objectif est de maximiser la marge entre les classes, c'est-à-dire la distance entre le point le plus proche de chaque classe et l'hyperplan.\n",
    "- **Avantages** : Efficace pour les espaces à haute dimension, fonctionne bien avec les classes non linéairement séparables avec l'utilisation de noyaux (kernels).\n",
    "- **Inconvénients** : Sensible au choix du kernel, moins efficace avec des datasets volumineux.\n",
    "\n",
    "#### **3.6. Naive Bayes**\n",
    "\n",
    "Le classifieur Naive Bayes est basé sur le théorème de Bayes avec une hypothèse d'indépendance conditionnelle entre les caractéristiques.\n",
    "\n",
    "- **Fonctionnement** : Il calcule la probabilité qu'une observation appartienne à chaque classe, puis sélectionne la classe avec la probabilité la plus élevée.\n",
    "- **Avantages** : Simple et rapide à entraîner, fonctionne bien avec des grandes datasets.\n",
    "- **Inconvénients** : Hypothèse d'indépendance souvent irréaliste, peut être suboptimal si les caractéristiques sont fortement corrélées.\n",
    "\n",
    "#### **3.7. Réseaux de Neurones**\n",
    "\n",
    "Les réseaux de neurones sont des modèles inspirés du cerveau humain, composés de couches de neurones artificiels.\n",
    "\n",
    "- **Fonctionnement** : Chaque neurone applique une fonction d'activation à une combinaison linéaire des entrées. Les réseaux de neurones peuvent avoir plusieurs couches pour capturer des relations complexes.\n",
    "- **Avantages** : Très puissant pour les données non structurées comme les images ou le texte, capable de modéliser des relations complexes.\n",
    "- **Inconvénients** : Long à entraîner, nécessite beaucoup de données et de puissance de calcul, difficile à interpréter.\n",
    "\n",
    "### 4. **Métriques d'Évaluation des Modèles de Classification**\n",
    "\n",
    "#### **Accuracy (Précision)**\n",
    "- Proportion de prédictions correctes sur l'ensemble des prédictions.\n",
    "\n",
    "#### **Precision (Précision)**\n",
    "- Proportion des vraies prédictions positives parmi toutes les prédictions positives.\n",
    "\n",
    "#### **Recall (Rappel)**\n",
    "- Proportion des vraies prédictions positives parmi tous les exemples positifs réels.\n",
    "\n",
    "#### **F1-Score**\n",
    "- Moyenne harmonique de la précision et du rappel, particulièrement utile pour les classes déséquilibrées.\n",
    "\n",
    "#### **Matrice de Confusion**\n",
    "- Tableau qui montre les prédictions correctes et incorrectes pour chaque classe.\n",
    "\n",
    "### 5. **Conclusion**\n",
    "\n",
    "La classification est une technique clé en machine learning, utilisée pour résoudre une grande variété de problèmes. Le choix de l'algorithme dépend du type de données, de la complexité du problème, et des ressources disponibles. Il est souvent utile de tester plusieurs algorithmes et d'utiliser des techniques comme la validation croisée pour évaluer leur performance avant de choisir le modèle final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1369de5",
   "metadata": {},
   "source": [
    "### Tarpaga\n",
    "- Présentation et explication du modèle KNN\n",
    "- Explication du mécanisme du modèle (Comment le modèle apprend)\n",
    "- Faire un exemple si possible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
